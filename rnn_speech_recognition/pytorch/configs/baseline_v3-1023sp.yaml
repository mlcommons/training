# Copyright (c) 2020, NVIDIA CORPORATION. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#
# ~5.8% WER on dev-clean after 100epochs with LR 1e-3
#

tokenizer:
    sentpiece_model: /datasets/sentencepieces/librispeech1023.model
    labels: [" ", "a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k", "l", "m",
             "n", "o", "p", "q", "r", "s", "t", "u", "v", "w", "x", "y", "z", "'"]

input_val:
  audio_dataset: &val_dataset
    sample_rate: &sample_rate 16000
    trim_silence: true
    normalize_transcripts: true

  filterbank_features: &val_features
    normalize: per_feature
    sample_rate: *sample_rate
    window_size: 0.02
    window_stride: 0.01
    window: hann
    n_fft: 512
    n_filt: &n_filt 80
    dither: 0.00001
  frame_splicing: &val_splicing
    frame_stacking: 3
    frame_subsampling: 3

# For training we keep samples < 16.7s and apply augmentation
input_train:
  audio_dataset:
    <<: *val_dataset
    max_duration: 16.7
    speed_perturbation:
        min_rate: 0.85
        max_rate: 1.15
        p: 1.0

  filterbank_features: *val_features
  frame_splicing: *val_splicing

  spec_augment:
    freq_masks: 2
    min_freq: 0
    max_freq: 20
    time_masks: 10
    min_time: 0
    max_time: 0.03

rnnt:
  in_feats: 240  # n_filt x frame_stacking

  enc_n_hid: 1024
  enc_pre_rnn_layers: 2
  enc_post_rnn_layers: 3
  enc_stack_time_factor: 2
  enc_dropout: 0.1

  pred_n_hid: 512
  pred_rnn_layers: 2
  pred_dropout: 0.3

  joint_n_hid: 512
  joint_dropout: 0.3

  forget_gate_bias: 1.0
